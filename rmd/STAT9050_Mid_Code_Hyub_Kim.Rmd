---
title: "STAT9050_Mid_Code_HyubKim"
author: "김협"
output: html_document
---

# STAT9050-01. 응용통계학 특수문제 I

## Part 1. 

### (a)
```{r}
library(survival)
library(MASS)
```


```{r}
# set seed
set.seed(42)

# setting
# sample size
n <- 30000

rho <- 0.5
gamma <- 1.5

beta1 <- log(2)
beta2 <- log(2)
beta3 <- -1
```


#### i). Generate $Z_1$, Z_2, W_1, and W_2.
```{r}
# Covariates Z1, Z2, W1, W2 

# Z1, Z2 생성
mean_vector <- c(0, 0)
cov_matrix <- matrix(c(1, 0.75, 0.75, 1), nrow = 2)
z_values <- mvrnorm(n = n, mu = mean_vector, Sigma = cov_matrix)

Z1 <- z_values[, 1]
Z2 <- z_values[, 2]

# W1, W2 생성
W1 <- rnorm(n, mean = 0, sd = 1)
W2 <- rbinom(n, size = 1, prob = 0.5)
```

#### ii). Generate u ~ uniform(0, 1)
```{r}
u <- runif(n, min = 0, max = 1)
```

#### iii). Since F(t) ~ uniform(0,1), u = 1-S(t)
- 이 식을 이용해 t에 대해 푸는 작업은 iv. 스텝에서 수행.
```{r}

```

#### iv). t를 구하는 식을 통해 T 생성
```{r}
lambda_t <- exp(beta1 * Z1 + beta2 * W1 + beta3 * W2)
T <- (-log(1 - u) / (lambda_t * rho))^(1 / gamma)
```

#### v). T 생성 반복
- 이미 이전 스텝에서 30,000번 반복 수행됨.
```{r}

```

#### Result).
```{r}
# 데이터 프레임 생성
data <- data.frame(T = T, Z1 = Z1, W1 = W1, W2 = W2)

# Cox 비례 위험 모형 적합
cox_model <- coxph(Surv(T) ~ Z1 + W1 + W2, data = data)
summary(cox_model)
```

#### 결과 해석
1. `coef`
- $Z_1$: $\beta_1 = 0.696734$
- $W_1$: $\beta_2 = 0.684798$
- $W_2$: $\beta_3 = −0.992539$
- $Z_1$, $W_1$, $W_2$ 각각이 실제 값인 $\log(2), \log(2), -1$과 가깝게 추정된 것을 확인할 수 있다.

2. `exp(coef)`
- $Z_1$: $2.0072 — Z1$이 1 단위 증가할 때, 위험률이 약 2배 증가함을 의미
- $W_1$: $1.9834 — W1$이 1 단위 증가할 때, 위험률이 약 1.98배 증가함을 의미
- $W_1$: $0.3706 — W2$가 1 단위 증가할 때, 위험률이 약 63$ 감소함을 의미

3. `se(coef)`, `Pr(>|z|)`
- $Z_1$: 0.006672
- $W_1$: 0.006683
- $W_2$: 0.012556
- 각 회귀계수의 표준 오차도 매우 낮고, p-valueeh <2e-16으로 매우 작은 것을 확인할 수 있음
- $Z_1, W_1, W_2$에 대한 계수들이 통계적으로 유의미하다는 것을 의미

4. `Concordance` (일치도)
- 0.742
- 이는 모델이 데이터의 순서를 얼마나 잘 예측하는지를 나타냄
- 일반적으로 0.5는 우연 수준, 1은 완벽한 예측을 의미하므로, 0.742는 비교적 높은 예측 성능을 의미

### (b)
```{r}
# 반복 횟수 설정
num_simulations <- 100

# 추정값과 표준 오차를 저장할 행렬 생성
beta_estimates <- matrix(NA, nrow = num_simulations, ncol = 3)
se_estimates <- matrix(NA, nrow = num_simulations, ncol = 3)
```


```{r}
# 100번 반복하여 Cox 모델 적합 및 추정값과 표준 오차 저장
for (i in 1:num_simulations) {
  # Step ii: u ~ uniform(0, 1) 생성
  u <- runif(n, min = 0, max = 1)
  
  # Step iv: T 생성
  T <- (-log(1 - u) / (lambda_t * rho))^(1 / gamma)
  
  # 데이터 프레임 생성
  data <- data.frame(T = T, Z1 = Z1, W1 = W1, W2 = W2)
  
  # Cox 모델 적합
  cox_model <- coxph(Surv(T) ~ Z1 + W1 + W2, data = data)
  
  # 추정값과 표준 오차 저장
  beta_estimates[i, ] <- cox_model$coefficients
  se_estimates[i, ] <- sqrt(diag(vcov(cox_model)))
}

# 각 추정값의 표본 평균과 표본 표준편차 계산
beta_means <- colMeans(beta_estimates)
se_means <- colMeans(se_estimates)
beta_sds <- apply(beta_estimates, 2, sd)
se_sds <- apply(se_estimates, 2, sd)

# 결과 출력
cat("100회 반복에 대한 추정 결과:\n")
cat("베타 추정값의 표본 평균: ", beta_means, "\n")
cat("베타 추정값의 표본 표준편차: ", beta_sds, "\n")
cat("표준 오차의 표본 평균: ", se_means, "\n")
cat("표준 오차의 표본 표준편차: ", se_sds, "\n")
```

#### 결과 해석
1. 베타 추정값의 표본 평균
- $\beta_1$의 추정값 표본 평균: 0.6931639 $\approx \log(2)$
- $\beta_2$의 추정값 표본 평균: 0.6933708 $\approx \log(2)$
- $\beta_3$의 추정값 표본 평균: −1.001591 $\approx -1$
- 모든 계수가 실제값에 근접하므로, 모델이 잘 추정되고 있음을 확인

2. 베타 추정값의 표본 표준편차
- $\beta_1$의 추정값 표본 표준편차: 0.007137426 
- $\beta_2$의 추정값 표본 표준편차: 0.00634256 
- $\beta_3$의 추정값 표본 표준편차: 0.01251695 
- 표본 표준편차가 크지 않으므로, 추정값의 변동성이 크지 않음을 의미

3. 표준 오차의 표본 평균, 표본 표준편차
- 각 추정값의 **표준 오차의 평균**을 추정된 값의 표준편차와 비교했을 때 비슷한 수준을 보임. 
- 따라서, 표준 오차 추정이 정확함을 나타내며, 일관되게 추정되고 있음을 알 수 있음.
- 또한 **표준 오차의 표본 표준편차** 값들이 작다는 것은 표준 오차 추정값이 반복마다 크게 변하지 않고 안정적이라는 것을 의미

### (c)
```{r}
# 목표 censoring rate
target_censor_rates <- c(0.1, 0.3, 0.9, 0.95, 0.99)
censor_params <- numeric(length(target_censor_rates))

# 큰 샘플 수를 사용하여 censoring rate을 안정적으로 추정
large_n <- 1e6

# (a)번에서 생성한 Z1, Z2, W1, W2 및 lambda_t를 기반으로 T 생성 (large_n 규모로 확장)
u <- runif(large_n, min = 0, max = 1)
T_large <- (-log(1 - u) / (lambda_t * rho))^(1 / gamma)

# 각 censoring rate율에 대해 적절한 C 파라미터 찾기
for (i in seq_along(target_censor_rates)) {
  target_rate <- target_censor_rates[i]
  
  # 초기값 설정
  lambda_c <- 0.1
  
  for (j in 1:100) {
    # censoring rate C 생성 (지수 분포)
    C <- rexp(large_n, rate = lambda_c)
    
    # censoring rate 계산
    censor_rate <- mean(T_large > C)
    
    # 목표 censoring rate과 비교하여 lambda_c 조정
    if (censor_rate < target_rate) {
      lambda_c <- lambda_c * 0.9  # censoring rate이 낮으면 감소
    } else if (censor_rate > target_rate) {
      lambda_c <- lambda_c * 1.1  # censoring rate이 높으면 증가
    } else {
      break
    }
  }
  
  # 최종 lambda_c 저장
  censor_params[i] <- lambda_c
  cat(sprintf("목표 censoring rate: %.0f%%, lambda_c: %.5f\n", target_rate * 100, lambda_c))
}

# 결과 출력
cat("각 censoring rate에 대한 최적의 lambda_c 값:\n")
censor_params
names(censor_params) <- paste0("Censor_", target_censor_rates * 100, "%")
censor_params

```
- 높은 censoring rate에 대해서 lambda_c가 0으로 수렴하고 있는 문제가 발생
- 반복수를 늘리고, lambda_c의 조정을 더 미세하게 수정해봄


```{r}
target_censor_rates <- c(0.1, 0.3, 0.9, 0.95, 0.99)
censor_params <- numeric(length(target_censor_rates))

# 큰 샘플 수를 사용하여 censoring rate을 안정적으로 추정
large_n <- 1e6

# (a)번에서 생성한 Z1, Z2, W1, W2 및 lambda_t를 기반으로 T 생성 (large_n 규모로 확장)
u <- runif(large_n, min = 0, max = 1)
T_large <- (-log(1 - u) / (lambda_t * rho))^(1 / gamma)

# 각 censoring rate에 대해 적절한 C 파라미터 찾기
for (i in seq_along(target_censor_rates)) {
  target_rate <- target_censor_rates[i]
  
  # 초기값 설정: 목표 censoring rate이 높을수록 더 작은 값으로 시작
  lambda_c <- ifelse(target_rate > 0.5, 0.00001, 0.1)
  
  # 반복적으로 censoring rate 맞추기
  for (j in 1:1000) {  # 최대 반복 횟수를 크게 늘려 더 정밀하게 조정
    # censoring time C 생성 (지수 분포)
    C <- rexp(large_n, rate = lambda_c)
    
    # censoring rate 계산
    censor_rate <- mean(T_large > C)
    
    # 목표 censoring rate과 비교하여 lambda_c 조정 (아주 세밀하게 조정)
    if (censor_rate < target_rate) {
      lambda_c <- lambda_c * 0.995  # censoring rate이 낮으면 더 미세하게 감소
    } else if (censor_rate > target_rate) {
      lambda_c <- lambda_c * 1.005  # censoring rate이 높으면 더 미세하게 증가
    } else {
      break
    }
  }
  
  # 최종 lambda_c 저장
  censor_params[i] <- lambda_c
  cat(sprintf("목표 censoring rate: %.0f%%, lambda_c: %.8f\n", target_rate * 100, lambda_c))
}

# 결과 출력
cat("각 censoring rate에 대한 최적의 lambda_c 값:\n")
censor_params
names(censor_params) <- paste0("Censor_", target_censor_rates * 100, "%")
censor_params
```
- 목표 ceonsoring rate 10%일 때, 더 안정적인 수치로 수렴한 것을 확인
- 목표 ceonsoring rate 30%일 때, 0보다 약간 큰 수치로 수렴한 것을 확인
- 목표 ceonsoring rate이 매우 클 때 (90%, 95%, 99%일 때), 0보다 아주 약간 큰 수치로 수렴한 것을 확인 (다만 0에 너무 가깝다.)

### (d)
```{r}

```




